# ğŸ™ï¸ Assistant Vocal Intelligent

Un assistant vocal local en **Python**, capable dâ€™Ã©couter, transcrire, rÃ©pondre et parler grÃ¢ce Ã  des modÃ¨les **OpenAI Whisper**, **Piper TTS** et **Gradio**.  
ConÃ§u pour fonctionner hors ligne et offrir une expÃ©rience fluide sur PC ou microcontrÃ´leur compatible.

---

## ğŸš€ FonctionnalitÃ©s principales

- ğŸ§ **Reconnaissance vocale (Speech-to-Text)**  
  BasÃ©e sur [Whisper](https://github.com/openai/whisper), avec accÃ©lÃ©ration GPU (CUDA si disponible).

- ğŸ—£ï¸ **SynthÃ¨se vocale (Text-to-Speech)**  
  PropulsÃ©e par [Piper TTS](https://github.com/rhasspy/piper), pour une voix naturelle et rapide.

- ğŸ§  **DÃ©tection de mot-clÃ© ("Hotword Detection")**  
  Utilise [Picovoice Porcupine](https://github.com/Picovoice/porcupine) pour activer lâ€™Ã©coute Ã  la voix.

- ğŸ’¬ **Interface graphique (UI)**  
  DÃ©veloppÃ©e avec [Gradio](https://gradio.app/) â€” une interface web moderne pour interagir avec lâ€™assistant.

- ğŸ§© **Architecture modulaire**  
  Les modules de reconnaissance, synthÃ¨se, interface et gestion systÃ¨me sont indÃ©pendants et extensibles.

---

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ run.py                     # Point d'entrÃ©e principal
â”œâ”€â”€ requirement.txt            # DÃ©pendances Python
â”œâ”€â”€ .gitignore                 # Fichiers/dossiers ignorÃ©s par Git
â”œâ”€â”€ README.md                  # Ce fichier
â”œâ”€â”€ CONTRIBUTING.md            # Guide de contribution
â””â”€â”€ src/
    â”œâ”€â”€ main.py                # Classe principale AssistantVocal
    â”œâ”€â”€ core/                  # Logique interne (STT, TTS, hotword, etc.)
    â”œâ”€â”€ ui/                    # Interface Gradio / console
    â”œâ”€â”€ utils/                 # Outils : logger, config, monitoring
    â””â”€â”€ config/                # Fichiers de configuration
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/<ton-utilisateur>/<ton-projet>.git
cd <ton-projet>
```

### 2ï¸âƒ£ CrÃ©er un environnement virtuel

```bash
python -m venv venv
source venv/bin/activate        # Linux / macOS
venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Installer les dÃ©pendances

```bash
pip install -r requirement.txt
```

> ğŸ’¡ Pour de meilleures performances, installe PyTorch avec CUDA si ton GPU le supporte :
> [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)

---

## â–¶ï¸ Utilisation

Lancer simplement :

```bash
python run.py
```

Lâ€™assistant :
- initialise la dÃ©tection vocale,
- Ã©coute le micro,
- transcrit les phrases dÃ©tectÃ©es,
- rÃ©pond via synthÃ¨se vocale et interface Gradio.

Les logs sont disponibles dans le fichier :
```
logs/assistant.log
```

---

## ğŸ§° Technologies principales

| Domaine | BibliothÃ¨que |
|----------|---------------|
| Reconnaissance vocale | `openai-whisper` |
| SynthÃ¨se vocale | `piper-tts` |
| DÃ©tection mot-clÃ© | `pvporcupine`, `pvrecorder` |
| Interface utilisateur | `gradio` |
| Monitoring systÃ¨me | `psutil` |
| Traitement audio | `pyaudio`, `librosa`, `numpy` |

---

## ğŸ§ª DÃ©veloppement

### Lancer en mode debug

```bash
python run.py --debug
```

### Ajouter un module
Chaque module suit la mÃªme logique :
- dÃ©finir une classe dÃ©diÃ©e (ex: `SpeechRecognizer`, `TextToSpeech`)
- dÃ©clarer son interface publique
- lâ€™enregistrer dans `AssistantVocal`

---

## ğŸ§‘â€ğŸ’» Contribuer

Les contributions sont bienvenues !  
Consultez le fichier [`CONTRIBUTING.md`](CONTRIBUTING.md) pour les bonnes pratiques et la gestion des issues/pull requests.

---

## ğŸªª Licence

Ce projet est distribuÃ© sous licence MIT.  
Voir le fichier `LICENSE` (Ã  ajouter si manquant).

---

## ğŸ§© Auteurs

- **Jean-Marc Renaud** â€” CrÃ©ateur & dÃ©veloppeur principal  
  Contributions ouvertes Ã  toute personne souhaitant amÃ©liorer le projet.

---
