import whisper
import numpy as np
import tempfile
import os
from typing import Optional
from ..utils.logger import logger

class SpeechRecognitionService:
    """Service de reconnaissance vocale avec Whisper."""
    
    def __init__(self, model_name: str = "base"):
        self.model_name = model_name
        self.model = None
        self.is_available = self._load_model()
        logger.info(f"SpeechRecognitionService initialis√© - Mod√®le: {model_name}")
    
    def _load_model(self) -> bool:
        """Charge le mod√®le Whisper."""
        try:
            logger.info(f"üîÑ Chargement du mod√®le Whisper '{self.model_name}'...")
            self.model = whisper.load_model(self.model_name)
            logger.info("‚úÖ Mod√®le Whisper charg√© avec succ√®s")
            return True
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le Whisper: {e}")
            return False

    def unload_model(self):
        """D√©charge le mod√®le Whisper de la m√©moire GPU."""
        try:
            if self.model and torch.cuda.is_available():
                del self.model
                self.model = None
                torch.cuda.empty_cache()
                logger.info("üóëÔ∏è Mod√®le Whisper d√©charg√©")
                return True
            elif self.model:
                del self.model
                self.model = None
                logger.info("üóëÔ∏è Mod√®le Whisper d√©charg√© (CPU)")
                return True
        except Exception as e:
            logger.error(f"Erreur d√©chargement mod√®le Whisper: {e}")
        return False

    def optimize_model_cache(self):
        """Optimise le cache du mod√®le."""
        try:
            if hasattr(self.model, 'cache_clear'):
                self.model.cache_clear()
                logger.info("üßπ Cache mod√®le Whisper nettoy√©")
            return True
        except Exception as e:
            logger.debug(f"Erreur optimisation cache Whisper: {e}")
            return False

    def load_model_on_demand(self):
        """Charge le mod√®le uniquement quand n√©cessaire."""
        if not self.model:
            logger.info("‚ö° Chargement mod√®le Whisper √† la demande")
            return self._load_model()
        return True
    
    def transcribe(self, audio_data: np.ndarray, language: str = "fr") -> str:
        """
        Transcrit l'audio en texte.
        
        Args:
            audio_data: Donn√©es audio numpy array (16kHz, int16)
            language: Langue de transcription (par d√©faut: fr)
            
        Returns:
            Texte transcrit
        """
        try:
            if not self.is_available or self.model is None:
                logger.warning("Whisper non disponible, retour texte simul√©")
                return self._simulate_transcription(audio_data)
            
            # Convertir int16 en float32
            if audio_data.dtype == np.int16:
                audio_float = audio_data.astype(np.float32) / 32768.0
            else:
                audio_float = audio_data.astype(np.float32)
            
            logger.info(f"üìù Transcription de {len(audio_float)} √©chantillons...")
            
            # Transcrire avec Whisper
            result = self.model.transcribe(
                audio_float,
                language=language,
                fp16=False  # D√©sactiver FP16 pour compatibilit√©
            )
            
            text = result.get("text", "").strip()
            logger.info(f"‚úÖ Transcription r√©ussie: {text}")
            
            return text
            
        except Exception as e:
            logger.error(f"‚ùå Erreur transcription: {e}")
            return ""
    
    def _simulate_transcription(self, audio_data: np.ndarray) -> str:
        """Simulation de transcription pour tests."""
        logger.warning("üîç Utilisation transcription simul√©e")
        return "Bonjour, comment allez-vous ?"
    
    def transcribe_file(self, file_path: str, language: str = "fr") -> str:
        """
        Transcrit un fichier audio.
        
        Args:
            file_path: Chemin du fichier audio
            language: Langue de transcription
            
        Returns:
            Texte transcrit
        """
        try:
            if not self.is_available or self.model is None:
                logger.warning("Whisper non disponible")
                return ""
            
            logger.info(f"üìù Transcription du fichier: {file_path}")
            
            result = self.model.transcribe(
                file_path,
                language=language,
                fp16=False
            )
            
            text = result.get("text", "").strip()
            logger.info(f"‚úÖ Transcription fichier r√©ussie: {text}")
            
            return text
            
        except Exception as e:
            logger.error(f"‚ùå Erreur transcription fichier: {e}")
            return ""
    
    def get_available_models(self) -> list:
        """Retourne la liste des mod√®les disponibles."""
        return ["tiny", "base", "small", "medium", "large"]
    
    def test_transcription(self) -> bool:
        """Teste la transcription."""
        try:
            # Cr√©er un court √©chantillon de test
            test_audio = np.zeros(16000, dtype=np.int16)  # 1 seconde de silence
            result = self.transcribe(test_audio)
            logger.info("‚úÖ Test transcription r√©ussi")
            return True
        except Exception as e:
            logger.error(f"‚ùå Test transcription √©chou√©: {e}")
            return False
