import psutil
import torch
import gc
import threading
import time
from typing import Dict, List, Optional
from ..utils.logger import logger

class PerformanceOptimizer:
    """Optimiseur de performance avanc√© pour l'assistant vocal."""
    
    def __init__(self):
        self.is_monitoring = False
        self.monitoring_thread = None
        self.performance_stats = {
            "cpu_usage": [],
            "memory_usage": [],
            "gpu_memory": [],
            "disk_io": [],
            "network_io": [],
            "response_times": []
        }
        self.alert_thresholds = {
            "cpu_max": 80.0,
            "memory_max": 85.0,
            "gpu_memory_max": 85.0,
            "disk_io_max": 90.0,
            "network_io_max": 100.0,  # MB/s
            "response_time_max": 5.0
        }
        self.model_cache = {}  # Cache pour les mod√®les
        self.last_optimization = time.time()
        self.optimization_cooldown = 60  # 1 minute entre optimisations
        logger.info("PerformanceOptimizer avanc√© initialis√©")
    
    def start_monitoring(self):
        """D√©marre le monitoring des performances."""
        if self.is_monitoring:
            logger.warning("Monitoring d√©j√† actif")
            return
        
        self.is_monitoring = True
        self.monitoring_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitoring_thread.start()
        logger.info("Monitoring des performances d√©marr√©")
    
    def stop_monitoring(self):
        """Arr√™te le monitoring des performances."""
        self.is_monitoring = False
        if self.monitoring_thread and self.monitoring_thread.is_alive():
            self.monitoring_thread.join(timeout=2.0)
        logger.info("Monitoring des performances arr√™t√©")
    
    def _monitor_loop(self):
        """Boucle de monitoring en arri√®re-plan."""
        last_disk_io = psutil.disk_io_counters()
        last_net_io = psutil.net_io_counters()
        
        while self.is_monitoring:
            try:
                # Collecter les statistiques
                stats = self._collect_stats(last_disk_io, last_net_io)
                
                # Mettre √† jour les compteurs pour le prochain cycle
                last_disk_io = psutil.disk_io_counters()
                last_net_io = psutil.net_io_counters()
                
                # Stocker les stats
                self._store_stats(stats)
                
                # V√©rifier les alertes
                alerts = self._check_alerts(stats)
                if alerts:
                    for alert in alerts:
                        logger.warning(f"üö® Performance: {alert}")
                
                # Auto-optimisation si n√©cessaire
                if self._should_auto_optimize(stats):
                    self._trigger_auto_optimization()
                
                # Pause de 5 secondes
                time.sleep(5)
                
            except Exception as e:
                logger.debug(f"Erreur monitoring: {e}")
                time.sleep(5)
    
    def _collect_stats(self, last_disk_io=None, last_net_io=None) -> Dict:
        """Collecte les statistiques syst√®me avanc√©es."""
        try:
            stats = {
                "timestamp": time.time(),
                "cpu_percent": psutil.cpu_percent(interval=0.1),
                "memory_percent": psutil.virtual_memory().percent,
                "memory_available_gb": psutil.virtual_memory().available / (1024**3),
                "memory_used_gb": psutil.virtual_memory().used / (1024**3)
            }
            
            # GPU stats si disponible
            if torch.cuda.is_available():
                try:
                    stats["gpu_memory_used_mb"] = torch.cuda.memory_allocated() / (1024**2)
                    stats["gpu_memory_reserved_mb"] = torch.cuda.memory_reserved() / (1024**2)
                    stats["gpu_memory_total_mb"] = torch.cuda.get_device_properties(0).total_memory / (1024**2)
                    stats["gpu_utilization"] = self._get_gpu_utilization()
                except Exception as e:
                    logger.debug(f"Erreur stats GPU: {e}")
            
            # I/O disque
            if last_disk_io:
                try:
                    current_disk_io = psutil.disk_io_counters()
                    read_bytes_per_sec = (current_disk_io.read_bytes - last_disk_io.read_bytes) / 5  # 5 secondes
                    write_bytes_per_sec = (current_disk_io.write_bytes - last_disk_io.write_bytes) / 5
                    stats["disk_read_mbps"] = read_bytes_per_sec / (1024**2)
                    stats["disk_write_mbps"] = write_bytes_per_sec / (1024**2)
                except Exception as e:
                    logger.debug(f"Erreur stats disque: {e}")
            
            # I/O r√©seau
            if last_net_io:
                try:
                    current_net_io = psutil.net_io_counters()
                    bytes_per_sec = (current_net_io.bytes_sent + current_net_io.bytes_recv - 
                                   last_net_io.bytes_sent - last_net_io.bytes_recv) / 5
                    stats["network_mbps"] = bytes_per_sec / (1024**2)
                except Exception as e:
                    logger.debug(f"Erreur stats r√©seau: {e}")
            
            return stats
            
        except Exception as e:
            logger.debug(f"Erreur collecte stats: {e}")
            return {}
    
    def _get_gpu_utilization(self) -> float:
        """R√©cup√®re l'utilisation GPU (simplifi√©)."""
        try:
            # Pour une impl√©mentation plus pr√©cise, vous pouvez utiliser nvidia-ml-py
            # Mais pour l'instant, on utilise une estimation basique
            if torch.cuda.is_available():
                # V√©rifier si des tensors CUDA sont actifs
                if torch.cuda.memory_allocated() > 0:
                    return 50.0  # Estimation
            return 0.0
        except Exception:
            return 0.0
    
    def _store_stats(self, stats: Dict):
        """Stocke les statistiques avec limitation."""
        if not stats:
            return
        
        # Ajouter aux listes (limiter √† 100 points)
        for key in ["cpu_percent", "memory_percent", "disk_read_mbps", "disk_write_mbps", "network_mbps"]:
            if key in stats:
                self.performance_stats[key].append(stats[key])
                if len(self.performance_stats[key]) > 100:
                    self.performance_stats[key] = self.performance_stats[key][-100:]
        
        # GPU memory
        if "gpu_memory_used_mb" in stats:
            self.performance_stats["gpu_memory"].append(stats["gpu_memory_used_mb"])
            if len(self.performance_stats["gpu_memory"]) > 100:
                self.performance_stats["gpu_memory"] = self.performance_stats["gpu_memory"][-100:]
    
    def _check_alerts(self, stats: Dict) -> List[str]:
        """V√©rifie les alertes de performance avanc√©es."""
        alerts = []
        
        if not stats:
            return alerts
        
        # CPU
        cpu_percent = stats.get("cpu_percent", 0)
        if cpu_percent > self.alert_thresholds["cpu_max"]:
            alerts.append(f"CPU √©lev√©: {cpu_percent:.1f}%")
        
        # M√©moire
        memory_percent = stats.get("memory_percent", 0)
        if memory_percent > self.alert_thresholds["memory_max"]:
            alerts.append(f"M√©moire √©lev√©e: {memory_percent:.1f}%")
        
        # GPU
        if "gpu_memory_used_mb" in stats and "gpu_memory_total_mb" in stats:
            gpu_percent = (stats["gpu_memory_used_mb"] / stats["gpu_memory_total_mb"]) * 100
            if gpu_percent > self.alert_thresholds["gpu_memory_max"]:
                alerts.append(f"GPU m√©moire √©lev√©e: {gpu_percent:.1f}%")
        
        # Disque I/O
        if "disk_read_mbps" in stats:
            if stats["disk_read_mbps"] > self.alert_thresholds["disk_io_max"]:
                alerts.append(f"Disque lecture √©lev√©e: {stats['disk_read_mbps']:.1f} MB/s")
        if "disk_write_mbps" in stats:
            if stats["disk_write_mbps"] > self.alert_thresholds["disk_io_max"]:
                alerts.append(f"Disque √©criture √©lev√©e: {stats['disk_write_mbps']:.1f} MB/s")
        
        # R√©seau I/O
        if "network_mbps" in stats:
            if stats["network_mbps"] > self.alert_thresholds["network_io_max"]:
                alerts.append(f"R√©seau √©lev√©: {stats['network_mbps']:.1f} MB/s")
        
        return alerts
    
    def optimize_memory(self, aggressive: bool = False):
        """Optimise l'utilisation m√©moire avanc√©e."""
        try:
            logger.info(f"üßπ Optimisation m√©moire {'agressive' if aggressive else 'normale'}")
            
            # Nettoyer le cache CUDA
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                if aggressive:
                    torch.cuda.ipc_collect()
                logger.info("üßπ Cache CUDA nettoy√©")
            
            # Forcer le garbage collector
            collected = gc.collect()
            logger.info(f"üßπ Garbage collection: {collected} objets")
            
            # Nettoyage plus agressif si demand√©
            if aggressive:
                # Nettoyer les caches Python
                import sys
                if hasattr(sys, 'clear_cache'):
                    sys.clear_cache()
                
                # Vider les caches de biblioth√®ques
                self._clear_library_caches()
            
            # V√©rifier la m√©moire
            memory = psutil.virtual_memory()
            logger.info(f"üìä M√©moire apr√®s optimisation: {memory.percent:.1f}%")
            
            return True
            
        except Exception as e:
            logger.error(f"Erreur optimisation m√©moire: {e}")
            return False
    
    def _clear_library_caches(self):
        """Nettoie les caches des biblioth√®ques."""
        try:
            # Whisper cache
            import whisper
            if hasattr(whisper, '_cache'):
                whisper._cache.clear()
            
            # NumPy cache
            import numpy as np
            if hasattr(np, 'clear_cache'):
                np.clear_cache()
                
        except Exception as e:
            logger.debug(f"Erreur nettoyage caches: {e}")
    
    def optimize_models(self, unload_unused: bool = True):
        """Optimise les mod√®les charg√©s."""
        try:
            logger.info("‚ö° Optimisation des mod√®les")
            
            # Nettoyer les caches
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # D√©charger les mod√®les inutilis√©s si demand√©
            if unload_unused and hasattr(self, '_unload_unused_models'):
                unloaded = self._unload_unused_models()
                if unloaded:
                    logger.info(f"üóëÔ∏è {unloaded} mod√®les d√©charg√©s")
            
            logger.info("‚úÖ Optimisation mod√®les termin√©e")
            return True
            
        except Exception as e:
            logger.error(f"Erreur optimisation mod√®les: {e}")
            return False
    
    def _unload_unused_models(self) -> int:
        """D√©charge les mod√®les inutilis√©s."""
        unloaded_count = 0
        try:
            # Ici vous pouvez impl√©menter la logique de d√©chargement
            # bas√©e sur le temps d'inactivit√© des mod√®les
            current_time = time.time()
            
            models_to_remove = []
            for model_name, model_info in self.model_cache.items():
                if current_time - model_info.get('last_used', 0) > 300:  # 5 minutes
                    models_to_remove.append(model_name)
            
            for model_name in models_to_remove:
                del self.model_cache[model_name]
                unloaded_count += 1
                logger.info(f"üóëÔ∏è Mod√®le {model_name} d√©charg√©")
                
        except Exception as e:
            logger.debug(f"Erreur d√©chargement mod√®les: {e}")
        
        return unloaded_count
    
    def get_performance_report(self) -> Dict:
        """Retourne un rapport de performance d√©taill√©."""
        try:
            # Statistiques r√©centes
            recent_stats = {}
            for key, values in self.performance_stats.items():
                if values:
                    recent_stats[key] = {
                        "current": values[-1] if values else 0,
                        "average": sum(values) / len(values) if values else 0,
                        "max": max(values) if values else 0,
                        "min": min(values) if values else 0,
                        "trend": self._calculate_trend(values) if len(values) > 1 else "stable"
                    }
            
            # Utilisation syst√®me actuelle
            current_stats = self._collect_stats()
            
            report = {
                "timestamp": time.time(),
                "recent_stats": recent_stats,
                "current_stats": current_stats,
                "alerts": self._check_alerts(current_stats),
                "recommendations": self._get_detailed_recommendations(current_stats),
                "system_health": self._calculate_system_health(current_stats),
                "optimization_history": self._get_optimization_history()
            }
            
            return report
            
        except Exception as e:
            logger.error(f"Erreur rapport performance: {e}")
            return {"error": str(e)}
    
    def _calculate_trend(self, values: List[float]) -> str:
        """Calcule la tendance d'une s√©rie de valeurs."""
        if len(values) < 2:
            return "stable"
        
        # Comparer les derni√®res valeurs avec les pr√©c√©dentes
        recent_avg = sum(values[-5:]) / min(5, len(values))
        previous_avg = sum(values[-10:-5]) / min(5, max(1, len(values) - 5))
        
        if recent_avg > previous_avg * 1.1:
            return "increasing"
        elif recent_avg < previous_avg * 0.9:
            return "decreasing"
        else:
            return "stable"
    
    def _calculate_system_health(self, current_stats: Dict) -> Dict:
        """Calcule la sant√© globale du syst√®me."""
        try:
            health_score = 100
            issues = []
            
            # CPU
            cpu_percent = current_stats.get("cpu_percent", 0)
            if cpu_percent > 80:
                health_score -= 20
                issues.append("CPU surcharg√©")
            elif cpu_percent > 60:
                health_score -= 10
            
            # M√©moire
            memory_percent = current_stats.get("memory_percent", 0)
            if memory_percent > 85:
                health_score -= 25
                issues.append("M√©moire critique")
            elif memory_percent > 70:
                health_score -= 15
                issues.append("M√©moire √©lev√©e")
            
            # GPU
            if "gpu_memory_used_mb" in current_stats and "gpu_memory_total_mb" in current_stats:
                gpu_percent = (current_stats["gpu_memory_used_mb"] / current_stats["gpu_memory_total_mb"]) * 100
                if gpu_percent > 85:
                    health_score -= 20
                    issues.append("GPU m√©moire √©lev√©e")
                elif gpu_percent > 70:
                    health_score -= 10
            
            return {
                "score": max(0, health_score),
                "status": self._get_health_status(health_score),
                "issues": issues
            }
        except Exception as e:
            logger.debug(f"Erreur calcul sant√©: {e}")
            return {"score": 50, "status": "unknown", "issues": []}
    
    def _get_health_status(self, score: int) -> str:
        """Retourne le statut de sant√© bas√© sur le score."""
        if score >= 80:
            return "excellent"
        elif score >= 60:
            return "good"
        elif score >= 40:
            return "fair"
        elif score >= 20:
            return "poor"
        else:
            return "critical"
    
    def _get_detailed_recommendations(self, current_stats: Dict) -> List[str]:
        """G√©n√®re des recommandations d√©taill√©es d'optimisation."""
        recommendations = []
        
        if not current_stats:
            return recommendations
        
        # CPU
        cpu_percent = current_stats.get("cpu_percent", 0)
        if cpu_percent > 80:
            recommendations.append("üìâ R√©duire charge CPU: fermer applications inutiles")
        elif cpu_percent > 60:
            recommendations.append("‚ö†Ô∏è CPU mod√©r√©ment charg√©: surveiller utilisation")
        
        # M√©moire
        memory_percent = current_stats.get("memory_percent", 0)
        memory_available = current_stats.get("memory_available_gb", 0)
        if memory_percent > 85:
            recommendations.append("üö® Lib√©rer m√©moire: red√©marrer assistant")
        elif memory_percent > 70:
            recommendations.append("üßπ Optimiser m√©moire: ex√©cuter gc.collect()")
        elif memory_available < 2:
            recommendations.append("üíæ M√©moire faible: lib√©rer espace disque")
        
        # GPU
        if "gpu_memory_used_mb" in current_stats and "gpu_memory_total_mb" in current_stats:
            gpu_percent = (current_stats["gpu_memory_used_mb"] / current_stats["gpu_memory_total_mb"]) * 100
            if gpu_percent > 85:
                recommendations.append("üéÆ Lib√©rer GPU: d√©charger mod√®les inutilis√©s")
            elif gpu_percent > 70:
                recommendations.append("‚ö†Ô∏è GPU charg√©: surveiller utilisation")
        
        # I/O disque
        if "disk_read_mbps" in current_stats:
            if current_stats["disk_read_mbps"] > 50:
                recommendations.append("üíæ Disque lecture intense: optimiser acc√®s fichiers")
        if "disk_write_mbps" in current_stats:
            if current_stats["disk_write_mbps"] > 50:
                recommendations.append("üíæ Disque √©criture intense: r√©duire √©critures")
        
        # R√©seau
        if "network_mbps" in current_stats:
            if current_stats["network_mbps"] > 50:
                recommendations.append("üåê R√©seau charg√©: v√©rifier connexions")
        
        # Recommandations g√©n√©rales
        if not recommendations:
            recommendations.extend([
                "‚úÖ Syst√®me en excellent √©tat",
                "üìà Performance optimale maintenue",
                "üîß Continuer monitoring r√©gulier"
            ])
        else:
            recommendations.append("üìä Surveiller tendances sur 5-10 minutes")
        
        return recommendations
    
    def _get_optimization_history(self) -> List[Dict]:
        """Retourne l'historique des optimisations."""
        # Pour l'instant, retourner un historique vide
        # Vous pouvez impl√©menter un syst√®me de logging persistant
        return []
    
    def auto_optimize(self, force: bool = False):
        """Optimisation automatique avanc√©e bas√©e sur les statistiques."""
        try:
            if not force and not self._should_optimize():
                return False
            
            current_stats = self._collect_stats()
            alerts = self._check_alerts(current_stats)
            
            optimizations_performed = []
            aggressive_mode = len(alerts) > 2  # Mode agressif si plusieurs alertes
            
            # Optimisation m√©moire
            if (current_stats.get("memory_percent", 0) > 75 or 
                len(alerts) > 1 or 
                aggressive_mode):
                logger.info(f"‚ö° Auto-optimisation m√©moire {'agressive' if aggressive_mode else 'normale'}")
                self.optimize_memory(aggressive=aggressive_mode)
                optimizations_performed.append("M√©moire optimis√©e")
            
            # Optimisation GPU
            if ("gpu_memory_used_mb" in current_stats and 
                "gpu_memory_total_mb" in current_stats):
                gpu_percent = (current_stats["gpu_memory_used_mb"] / current_stats["gpu_memory_total_mb"]) * 100
                if gpu_percent > 75:
                    logger.info("‚ö° Auto-optimisation GPU")
                    self.optimize_models()
                    optimizations_performed.append("GPU optimis√©")
            
            # D√©chargement mod√®les inutilis√©s
            if len(self.model_cache) > 5:  # Si plus de 5 mod√®les en cache
                unloaded = self._unload_unused_models()
                if unloaded > 0:
                    optimizations_performed.append(f"{unloaded} mod√®les d√©charg√©s")
            
            self.last_optimization = time.time()
            
            if optimizations_performed:
                logger.info(f"‚úÖ Auto-optimisations: {', '.join(optimizations_performed)}")
                return True
            else:
                logger.info("‚úÖ Pas d'optimisations n√©cessaires")
                return False
                
        except Exception as e:
            logger.error(f"Erreur auto-optimisation: {e}")
            return False
    
    def _should_optimize(self) -> bool:
        """V√©rifie si une optimisation est n√©cessaire."""
        # Ne pas optimiser trop fr√©quemment
        if time.time() - self.last_optimization < self.optimization_cooldown:
            return False
        
        # V√©rifier si des alertes sont actives
        current_stats = self._collect_stats()
        alerts = self._check_alerts(current_stats)
        
        return len(alerts) > 0
    
    def _should_auto_optimize(self, stats: Dict) -> bool:
        """V√©rifie si une auto-optimisation est n√©cessaire."""
        # Optimiser si plusieurs ressources sont surcharg√©es
        alert_count = len(self._check_alerts(stats))
        return alert_count >= 2
    
    def _trigger_auto_optimization(self):
        """D√©clenche une optimisation automatique."""
        logger.info("‚ö° D√©clenchement auto-optimisation")
        threading.Thread(target=self.auto_optimize, daemon=True).start()
    
    def get_resource_usage(self) -> Dict:
        """Retourne l'utilisation actuelle des ressources d√©taill√©e."""
        try:
            stats = self._collect_stats()
            usage = {
                "cpu": f"{stats.get('cpu_percent', 0):.1f}%",
                "memory": f"{stats.get('memory_percent', 0):.1f}% ({stats.get('memory_available_gb', 0):.2f}GB dispo)",
                "memory_used": f"{stats.get('memory_used_gb', 0):.2f}GB"
            }
            
            if "gpu_memory_used_mb" in stats and "gpu_memory_total_mb" in stats:
                gpu_percent = (stats["gpu_memory_used_mb"] / stats["gpu_memory_total_mb"]) * 100
                usage["gpu"] = f"{gpu_percent:.1f}% ({stats['gpu_memory_used_mb']:.0f}MB/{stats['gpu_memory_total_mb']:.0f}MB)"
                if "gpu_utilization" in stats:
                    usage["gpu_utilization"] = f"{stats['gpu_utilization']:.1f}%"
            
            if "disk_read_mbps" in stats:
                usage["disk_io"] = f"R:{stats['disk_read_mbps']:.1f}MB/s W:{stats['disk_write_mbps']:.1f}MB/s"
            
            if "network_mbps" in stats:
                usage["network"] = f"{stats['network_mbps']:.1f}MB/s"
            
            return usage
            
        except Exception as e:
            logger.error(f"Erreur usage ressources: {e}")
            return {"error": str(e)}
    
    def set_thresholds(self, **thresholds):
        """D√©finit les seuils d'alerte personnalis√©s."""
        for key, value in thresholds.items():
            if key in self.alert_thresholds:
                old_value = self.alert_thresholds[key]
                self.alert_thresholds[key] = value
                logger.info(f"üîß Seuil {key}: {old_value} ‚Üí {value}")
    
    def get_optimization_profile(self) -> Dict:
        """Retourne le profil d'optimisation actuel."""
        return {
            "thresholds": self.alert_thresholds.copy(),
            "cooldown": self.optimization_cooldown,
            "cached_models": len(self.model_cache),
            "monitoring_active": self.is_monitoring,
            "last_optimization": self.last_optimization
        }
    
    def set_optimization_profile(self, profile: Dict):
        """D√©finit le profil d'optimisation."""
        if "thresholds" in profile:
            self.alert_thresholds.update(profile["thresholds"])
        if "cooldown" in profile:
            self.optimization_cooldown = profile["cooldown"]
        logger.info("‚úÖ Profil d'optimisation mis √† jour")
