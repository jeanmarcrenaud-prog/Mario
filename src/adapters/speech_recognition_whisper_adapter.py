from __future__ import annotations
import numpy as np
from typing import Any
from ..interfaces.speech_recognition import ISpeechRecognitionAdapter
from ..utils.logger import logger


class WhisperSpeechRecognitionAdapter(ISpeechRecognitionAdapter):
    """Adaptateur concret pour Whisper."""

    def __init__(self, model_name: str = "base"):
        self.model_name = model_name
        self.model = None
        self.load_model()
        logger.info(f"WhisperSpeechRecognitionAdapter initialisÃ© - ModÃ¨le: {model_name}")

    def load_model(self) -> None:
        """Charge le modÃ¨le Whisper."""
        try:
            import whisper
            logger.info(f"ğŸ”„ Chargement du modÃ¨le Whisper '{self.model_name}'...")
            self.model = whisper.load_model(self.model_name)
            logger.info("âœ… ModÃ¨le Whisper chargÃ© avec succÃ¨s")
        except Exception as e:
            logger.error(f"âŒ Erreur chargement modÃ¨le Whisper: {e}")

    def unload_model(self) -> None:
        """DÃ©charge le modÃ¨le Whisper de la mÃ©moire GPU."""
        try:
            import torch
            if self.model and torch.cuda.is_available():
                del self.model
                self.model = None
                torch.cuda.empty_cache()
                logger.info("ğŸ—‘ï¸ ModÃ¨le Whisper dÃ©chargÃ©")
            elif self.model:
                del self.model
                self.model = None
                logger.info("ğŸ—‘ï¸ ModÃ¨le Whisper dÃ©chargÃ© (CPU)")
        except Exception as e:
            logger.error(f"Erreur dÃ©chargement modÃ¨le Whisper: {e}")

    def transcribe_array(self, audio: Any, **kwargs: Any) -> str:
        """Transcrit un tableau numpy d'audio en texte."""
        try:
            if self.model is None:
                return ""

            import whisper
            # Convertir int16 en float32
            if audio.dtype == np.int16:
                audio_float = audio.astype(np.float32) / 32768.0
            else:
                audio_float = audio.astype(np.float32)

            language = kwargs.get("language", "fr")
            logger.info(f"ğŸ“ Transcription de {len(audio_float)} Ã©chantillons...")

            # Transcrire avec Whisper
            result = self.model.transcribe(
                audio_float,
                language=language,
                fp16=False  # DÃ©sactiver FP16 pour compatibilitÃ©
            )

            text = result.get("text", "").strip()
            logger.info(f"âœ… Transcription rÃ©ussie: {text}")

            return text

        except Exception as e:
            logger.error(f"âŒ Erreur transcription: {e}")
            return ""

    def transcribe_file(self, path: str, **kwargs: Any) -> str:
        """Transcrit un fichier audio en texte."""
        try:
            if self.model is None:
                return ""

            import whisper
            language = kwargs.get("language", "fr")
            logger.info(f"ğŸ“ Transcription du fichier: {path}")

            result = self.model.transcribe(
                path,
                language=language,
                fp16=False
            )

            text = result.get("text", "").strip()
            logger.info(f"âœ… Transcription fichier rÃ©ussie: {text}")

            return text

        except Exception as e:
            logger.error(f"âŒ Erreur transcription fichier: {e}")
            return ""

    def get_available_models(self) -> list[str]:
        """Retourne la liste des modÃ¨les Whisper disponibles."""
        return ["tiny", "base", "small", "medium", "large"]
