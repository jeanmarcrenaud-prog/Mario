"""
Interface Web Gradio pour l'Assistant Vocal Intelligent
"""

import gradio as gr
from gradio import themes
import threading
import time
import json
from typing import List, Dict, Any, Optional, Tuple
from ..utils.logger import logger
from ..controllers.audio_controller import AudioController

class GradioWebInterface:
    """
    Interface web Gradio avancÃ©e pour l'assistant vocal.
    """
    
    def __init__(self, assistant_controller):
        self.assistant = assistant_controller
        self.demo = None
        self.chat_history = []
        self.audio_controller = AudioController()
        self._initialize_components()
        logger.info("GradioWebInterface initialisÃ©")
    
    def _initialize_components(self):
        """Initialise les composants de l'interface."""
        self.app_state = None
        self.status_text = None
        self.system_stats = None
        self.chatbot = None
        self.user_input = None
        # ... autres composants
    
    def create_interface(self) -> gr.Blocks:
        """CrÃ©e l'interface Gradio complÃ¨te."""
        with gr.Blocks(title="Assistant Vocal Intelligent") as demo:
            self.demo = demo
            self._setup_state()
            self._create_layout()
            self._setup_events()
            demo.load(self._on_interface_load, outputs=[self.status_text, self.system_stats])
        
        logger.info("Interface Gradio crÃ©Ã©e")
        return demo
    
    def _setup_state(self):
        """Configure l'Ã©tat de l'application."""
        self.app_state = gr.State({
            "is_listening": False,
            "current_model": self.assistant.settings.llm_model,
            "current_voice": self.assistant.settings.voice_name,
            "recording": False
        })
    
    def _create_layout(self):
        """CrÃ©e la disposition principale de l'interface."""
        self._create_header()
        with gr.Row():
            with gr.Column(scale=1):
                self._create_control_panel()
            with gr.Column(scale=3):
                self._create_main_tabs()
    
    def _create_header(self):
        """CrÃ©e l'en-tÃªte de l'interface."""
        with gr.Row():
            gr.Markdown("""
            # ğŸ¤ Assistant Vocal Intelligent
            ## Votre compagnon IA avec reconnaissance et synthÃ¨se vocale
            """)
    
    def _create_control_panel(self):
        """CrÃ©e le panneau de contrÃ´le."""
        gr.Markdown("## âš™ï¸ Configuration")
        self._create_status_section()
        self._create_audio_controls()
        self._create_ai_controls()
        self._create_system_stats()
    
    def _create_status_section(self):
        """CrÃ©e la section de statut."""
        with gr.Group():
            self.status_text = gr.Textbox(
                label="ğŸ“Š Statut",
                lines=4,
                value="ğŸŸ¢ Interface chargÃ©e - PrÃªt Ã  dÃ©marrer",
                interactive=False
            )
            
            with gr.Row():
                self.start_btn = gr.Button("â–¶ï¸ DÃ©marrer", variant="primary", scale=1)
                self.stop_btn = gr.Button("â¹ï¸ ArrÃªter", variant="stop", scale=1)
    
    def _create_audio_controls(self):
        """CrÃ©e les contrÃ´les audio."""
        with gr.Accordion("ğŸ¤ Audio", open=True):
            self.mic_dropdown = gr.Dropdown(
                label="Microphone",
                choices=self._get_microphone_choices(),
                value=self._get_default_microphone(),
                interactive=True
            )
            
            self.voice_dropdown = gr.Dropdown(
                label="ğŸ—£ï¸ Voix",
                choices=self._get_voice_choices(),
                value=self._get_default_voice(),
                interactive=True
            )
            
            self.speed_slider = gr.Slider(
                label="â© Vitesse de parole",
                minimum=0.5,
                maximum=2.0,
                value=1.0,
                step=0.1
            )
    
    def _create_ai_controls(self):
        """CrÃ©e les contrÃ´les d'intelligence artificielle."""
        with gr.Accordion("ğŸ¤– Intelligence", open=True):
            self.model_dropdown = gr.Dropdown(
                label="ModÃ¨le IA",
                choices=self._get_model_choices(),
                value=self._get_default_model(),
                interactive=True
            )
            
            self.temperature_slider = gr.Slider(
                label="ğŸŒ¡ï¸ CrÃ©ativitÃ©",
                minimum=0.0,
                maximum=1.0,
                value=0.7,
                step=0.1
            )
    
    def _create_system_stats(self):
        """CrÃ©e la section des statistiques systÃ¨me."""
        with gr.Group():
            self.system_stats = gr.Textbox(
                label="ğŸ–¥ï¸ SystÃ¨me",
                lines=3,
                interactive=False
            )
            
            self.refresh_stats_btn = gr.Button("ğŸ”„ Actualiser stats", size="sm")
    
    def _create_main_tabs(self):
        """CrÃ©e les onglets principaux."""
        with gr.Tabs():
            self._create_conversation_tab()
            self._create_files_tab()
            self._create_prompts_tab()
            self._create_settings_tab()
    
    def _create_conversation_tab(self):
        """CrÃ©e l'onglet de conversation."""
        with gr.Tab("ğŸ’¬ Conversation"):
            self._build_chat_interface()
            self._build_voice_commands()
    
    def _build_chat_interface(self):
        """Construit l'interface de chat."""
        self.chatbot = gr.Chatbot(label="Discussion", height=400)
        
        with gr.Row():
            self.user_input = gr.Textbox(
                label="Votre message",
                placeholder="Tapez votre message ou parlez aprÃ¨s avoir dit 'Mario'...",
                scale=4,
                lines=2
            )
            
            with gr.Column(scale=1):
                self.send_btn = gr.Button("ğŸ“¤ Envoyer", variant="primary")
                self.clear_btn = gr.Button("ğŸ§¹ Effacer", size="sm")
                self.refresh_chat_btn = gr.Button("ğŸ”„ Actualiser", size="sm")
    
    def _build_voice_commands(self):
        """Construit les commandes vocales."""
        with gr.Group():
            gr.Markdown("### ğŸ¤ Commandes vocales")
            with gr.Row():
                self.record_btn = gr.Button("ğŸ¤ Enregistrer", variant="secondary")
                self.listen_btn = gr.Button("ğŸ‘‚ Ã‰couter", variant="secondary")
            
            self.voice_command_status = gr.Textbox(
                label="Statut vocal",
                value="PrÃªt",
                interactive=False
            )
    
    def _create_files_tab(self):
        """CrÃ©e l'onglet de gestion des fichiers."""
        with gr.Tab("ğŸ“ Fichiers"):
            self._build_file_analysis_interface()
            self._build_project_analysis_interface()
            self._build_analysis_history()
    
    def _build_file_analysis_interface(self):
        """Construit l'interface d'analyse de fichiers."""
        gr.Markdown("## ğŸ“ Analyse de fichiers et projets avec IA")
        
        with gr.Tabs():
            with gr.Tab("ğŸ“„ Fichiers individuels"):
                with gr.Row():
                    with gr.Column():
                        self.file_upload = gr.File(
                            label="Glissez-dÃ©posez des fichiers",
                            file_types=[".txt", ".py", ".md", ".json", ".csv", ".html", ".css", ".js"],
                            type="filepath"
                        )
                        
                        with gr.Row():
                            self.analyze_btn = gr.Button("ğŸ” Analyser avec IA", variant="primary")
                            self.summarize_btn = gr.Button("ğŸ“ RÃ©sumer", variant="secondary")
                    
                    with gr.Column():
                        self.file_result = gr.Textbox(
                            label="RÃ©sultat de l'analyse",
                            lines=10,
                            interactive=False
                        )
    
    def _build_project_analysis_interface(self):
        """Construit l'interface d'analyse de projets."""
        with gr.Tab("ğŸ—ï¸ Projets complets"):
            with gr.Row():
                with gr.Column():
                    self._build_project_input_section()
                    self._build_project_analysis_controls()
                
                with gr.Column():
                    self.project_result = gr.Textbox(
                        label="Rapport d'analyse du projet",
                        lines=15,
                        interactive=False
                    )
            
            self._build_project_summary_section()
    
    def _build_project_input_section(self):
        """Construit la section d'entrÃ©e du projet."""
        self.project_path = gr.Textbox(
            label="Chemin du projet",
            placeholder="C:/chemin/vers/votre/projet ou laissez vide pour le dossier courant",
            value=".",
            interactive=True
        )
        
        self.current_dir_btn = gr.Button("ğŸ“‚ Utiliser dossier courant", size="sm")
    
    def _build_project_analysis_controls(self):
        """Construit les contrÃ´les d'analyse de projet."""
        with gr.Row():
            self.analyze_project_btn = gr.Button("ğŸ” Analyser projet", variant="primary", scale=2)
            self.export_json_btn = gr.Button("ğŸ’¾ Export JSON", scale=1)
            self.export_md_btn = gr.Button("ğŸ“„ Export Markdown", scale=1)
        
        self.project_depth = gr.Slider(
            label="Profondeur d'analyse",
            minimum=1,
            maximum=5,
            value=2,
            step=1
        )
    
    def _build_project_summary_section(self):
        """Construit la section de rÃ©sumÃ© du projet."""
        with gr.Group():
            gr.Markdown("### ğŸ“Š RÃ©sumÃ© de l'analyse")
            with gr.Row():
                self.project_summary = gr.Textbox(
                    label="RÃ©sumÃ©",
                    lines=3,
                    interactive=False
                )
            
            with gr.Row():
                self.key_points = gr.Dataframe(
                    label="Points clÃ©s",
                    headers=["Point important"],
                    datatype=["str"],
                    interactive=False
                )
    
    def _build_analysis_history(self):
        """Construit l'historique des analyses."""
        gr.Markdown("### ğŸ“ˆ Historique des analyses")
        self.analysis_history = gr.Dataframe(
            label="Analyses rÃ©centes",
            headers=["Type", "Cible", "Date", "Statut"],
            datatype=["str", "str", "str", "str"],
            interactive=False
        )
    
    def _create_prompts_tab(self):
        """CrÃ©e l'onglet de gestion des prompts personnalisÃ©s."""
        with gr.Tab("ğŸ¯ Prompts"):
            self._build_prompt_library()
            self._build_prompt_editor()
            self._build_prompt_preview()
            self._build_prompt_advanced_config()
    
    def _build_prompt_library(self):
        """Construit la bibliothÃ¨que de prompts."""
        gr.Markdown("## ğŸ¯ Prompts PersonnalisÃ©s")
        gr.Markdown("CrÃ©ez et utilisez des prompts spÃ©cialisÃ©s pour des tÃ¢ches rÃ©currentes.")
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“‹ BibliothÃ¨que de Prompts")
                self.prompt_list = gr.Dropdown(
                    label="Prompts sauvegardÃ©s",
                    choices=self._get_saved_prompts(),
                    interactive=True
                )
                
                with gr.Row():
                    self.load_prompt_btn = gr.Button("ğŸ“¥ Charger")
                    self.delete_prompt_btn = gr.Button("ğŸ—‘ï¸ Supprimer")
                
                self._build_prompt_categories()
    
    def _build_prompt_categories(self):
        """Construit les catÃ©gories de prompts."""
        prompt_categories = [
            "Analyse de code", "RÃ©sumÃ© de texte", "Explication technique",
            "GÃ©nÃ©ration de documentation", "Correction de bugs",
            "Optimisation de code", "Traduction", "CrÃ©ation de contenu"
        ]
        
        self.prompt_category = gr.Dropdown(
            label="CatÃ©gorie",
            choices=prompt_categories,
            value="Analyse de code",
            interactive=True
        )
    
    def _build_prompt_editor(self):
        """Construit l'Ã©diteur de prompts."""
        with gr.Column(scale=2):
            gr.Markdown("### âœï¸ CrÃ©ation/Ã‰dition de Prompt")
            self.prompt_name = gr.Textbox(
                label="Nom du prompt",
                placeholder="Ex: Analyse code Python",
                max_lines=1
            )
            
            self.prompt_description = gr.Textbox(
                label="Description",
                placeholder="Description courte de ce que fait ce prompt",
                lines=2
            )
            
            self.prompt_template = gr.Textbox(
                label="Template du prompt",
                placeholder=self._get_prompt_template_placeholder(),
                lines=10,
                max_lines=15
            )
            
            self._build_prompt_variables_editor()
    
    def _get_prompt_template_placeholder(self) -> str:
        """Retourne le placeholder pour le template de prompt."""
        return """Utilisez {input} pour le contenu utilisateur
Exemple:
Analysez ce code et expliquez sa fonction:
{input}

Fournissez:
1. RÃ©sumÃ© de la fonctionnalitÃ©
2. Points clÃ©s de l'implÃ©mentation
3. Suggestions d'amÃ©lioration"""
    
    def _build_prompt_variables_editor(self):
        """Construit l'Ã©diteur de variables de prompt."""
        gr.Markdown("### ğŸ“ Variables personnalisÃ©es")
        self.prompt_variables = gr.Textbox(
            label="Variables supplÃ©mentaires (sÃ©parÃ©es par des virgules)",
            placeholder="langage,framework,version",
            value=""
        )
        
        with gr.Row():
            self.save_prompt_btn = gr.Button("ğŸ’¾ Sauvegarder", variant="primary")
            self.test_prompt_btn = gr.Button("ğŸ§ª Tester")
            self.clear_prompt_btn = gr.Button("ğŸ§¹ Effacer")
    
    def _build_prompt_preview(self):
        """Construit la prÃ©visualisation du prompt."""
        with gr.Group():
            gr.Markdown("### ğŸ¯ Test du Prompt")
            
            with gr.Row():
                self._build_prompt_input_section()
                self._build_prompt_preview_section()
            
            self.prompt_test_result = gr.Textbox(
                label="RÃ©sultat du test",
                lines=6,
                interactive=False
            )
            
            self.use_in_chat_btn = gr.Button("ğŸ’¬ Utiliser dans le chat")
    
    def _build_prompt_input_section(self):
        """Construit la section d'entrÃ©e du prompt."""
        with gr.Column():
            self.prompt_input = gr.Textbox(
                label="Contenu d'entrÃ©e",
                placeholder="Entrez le texte/code Ã  analyser...",
                lines=5
            )
            
            self.prompt_custom_vars = gr.Textbox(
                label="Valeurs des variables (format: var1=valeur1,var2=valeur2)",
                placeholder="langage=Python,framework=FastAPI",
                lines=2
            )
    
    def _build_prompt_preview_section(self):
        """Construit la section de prÃ©visualisation du prompt."""
        with gr.Column():
            self.prompt_preview = gr.Textbox(
                label="Prompt gÃ©nÃ©rÃ©",
                lines=8,
                interactive=False
            )
    
    def _build_prompt_advanced_config(self):
        """Construit la configuration avancÃ©e des prompts."""
        with gr.Accordion("âš™ï¸ Configuration avancÃ©e", open=False):
            with gr.Row():
                self.prompt_temperature = gr.Slider(
                    label="TempÃ©rature",
                    minimum=0.0,
                    maximum=1.0,
                    value=0.7,
                    step=0.1
                )
                
                self.prompt_max_tokens = gr.Number(
                    label="Tokens maximum",
                    value=2000,
                    precision=0
                )
            
            self.prompt_system_message = gr.Textbox(
                label="Message systÃ¨me (optionnel)",
                placeholder="Instructions supplÃ©mentaires pour l'IA",
                lines=3
            )
        
        self._setup_prompt_events()
    
    def _create_settings_tab(self):
        """CrÃ©e l'onglet des paramÃ¨tres avancÃ©s."""
        with gr.Tab("ğŸ”§ ParamÃ¨tres"):
            self._build_settings_interface()
    
    def _build_settings_interface(self):
        """Construit l'interface des paramÃ¨tres."""
        gr.Markdown("## ğŸ”§ ParamÃ¨tres avancÃ©s")
        
        with gr.Tabs():
            self._build_system_settings_tab()
            self._build_audio_settings_tab()
            self._build_monitoring_tab()
            self._build_logs_tab()
    
    def _build_system_settings_tab(self):
        """Construit l'onglet de configuration systÃ¨me."""
        with gr.Tab("ğŸ–¥ï¸ SystÃ¨me"):
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ›ï¸ ParamÃ¨tres systÃ¨me")
                    self.auto_start_checkbox = gr.Checkbox(
                        label="DÃ©marrage automatique",
                        value=True
                    )
                    
                    self.web_port_number = gr.Number(
                        label="Port Web",
                        value=self.assistant.settings.web_port,
                        precision=0
                    )
                    
                    self.save_settings_btn = gr.Button("ğŸ’¾ Sauvegarder")
                
                with gr.Column():
                    gr.Markdown("### ğŸ“ˆ Performance")
                    self.performance_info = gr.Textbox(
                        label="Informations de performance",
                        lines=8,
                        interactive=False
                    )
                    
                    with gr.Row():
                        self.test_all_btn = gr.Button("ğŸ§ª Tester tous les services")
                        self.optimize_btn = gr.Button("âš¡ Optimiser", variant="primary")
    
    def _build_audio_settings_tab(self):
        """Construit l'onglet de configuration audio."""
        with gr.Tab("ğŸ”Š Audio"):
            self._build_audio_configuration()
    
    def _build_audio_configuration(self):
        """Construit la configuration audio complÃ¨te."""
        gr.Markdown("### ğŸ”Š Configuration Audio")
        
        with gr.Row():
            self._build_audio_input_section()
            self._build_audio_output_section()
        
        self._build_advanced_audio_settings()
        self._build_audio_control_buttons()
        self._setup_audio_events()
    
    def _build_audio_input_section(self):
        """Construit la section d'entrÃ©e audio."""
        with gr.Column():
            gr.Markdown("#### ğŸ¤ EntrÃ©e Audio")
            self.audio_mic_dropdown = gr.Dropdown(
                label="Microphone (pÃ©riphÃ©riques recommandÃ©s)",
                choices=self._get_microphone_choices(),
                value=self._get_default_microphone(),
                interactive=True,
                allow_custom_value=True
            )
            
            self.show_all_mics_btn = gr.Button("ğŸ” Voir tous les microphones", size="sm")
            self.all_mics_dropdown = gr.Dropdown(
                label="Tous les microphones (avancÃ©)",
                choices=self._get_all_audio_devices("input"),
                visible=False,
                interactive=True,
                allow_custom_value=True
            )
            
            self.test_mic_btn = gr.Button("ğŸ¤ Tester le microphone", variant="secondary")
            self.mic_test_status = gr.Textbox(
                label="Test microphone",
                lines=2,
                interactive=False,
                value="Cliquez pour tester"
            )
    
    def _build_audio_output_section(self):
        """Construit la section de sortie audio."""
        with gr.Column():
            gr.Markdown("#### ğŸ”ˆ Sortie Audio")
            self.audio_output_dropdown = gr.Dropdown(
                label="Sortie audio (pÃ©riphÃ©riques recommandÃ©s)",
                choices=self._get_audio_output_choices(),
                value=self._get_default_audio_output(),
                interactive=True
            )
            
            self.show_all_outputs_btn = gr.Button("ğŸ” Voir toutes les sorties", size="sm")
            self.all_outputs_dropdown = gr.Dropdown(
                label="Toutes les sorties audio (avancÃ©)",
                choices=self._get_all_audio_devices("output"),
                visible=False,
                interactive=True
            )
            
            self.test_speaker_btn = gr.Button("ğŸ”Š Tester la sortie", variant="secondary")
            self.speaker_test_status = gr.Textbox(
                label="Test sortie audio",
                lines=2,
                interactive=False,
                value="Cliquez pour tester"
            )
    
    def _build_advanced_audio_settings(self):
        """Construit les paramÃ¨tres audio avancÃ©s."""
        with gr.Accordion("âš™ï¸ ParamÃ¨tres audio avancÃ©s", open=False):
            with gr.Row():
                self.audio_volume = gr.Slider(
                    label="ğŸ”Š Volume gÃ©nÃ©ral",
                    minimum=0.0,
                    maximum=1.0,
                    value=0.8,
                    step=0.1
                )
                
                self.mic_sensitivity = gr.Slider(
                    label="ğŸ¤ SensibilitÃ© microphone",
                    minimum=0.1,
                    maximum=2.0,
                    value=1.0,
                    step=0.1
                )
            
            with gr.Row():
                self.silence_delay = gr.Slider(
                    label="â±ï¸ DÃ©lai de silence (secondes)",
                    minimum=0.5,
                    maximum=5.0,
                    value=2.0,
                    step=0.5
                )
                
                self.vad_threshold = gr.Slider(
                    label="ğŸ“Š Seuil dÃ©tection vocale",
                    minimum=0.1,
                    maximum=0.9,
                    value=0.5,
                    step=0.1
                )
    
    def _build_audio_control_buttons(self):
        """Construit les boutons de contrÃ´le audio."""
        with gr.Row():
            self.save_audio_btn = gr.Button("ğŸ’¾ Sauvegarder paramÃ¨tres audio", variant="primary")
            self.apply_audio_btn = gr.Button("ğŸ”„ Appliquer maintenant")
            self.reset_audio_btn = gr.Button("ğŸ”„ RÃ©initialiser")
        
        self.audio_settings_status = gr.Textbox(
            label="Statut audio",
            lines=3,
            interactive=False,
            value="Configuration audio prÃªte"
        )
    
    def _build_monitoring_tab(self):
        """Construit l'onglet de monitoring."""
        with gr.Tab("ğŸ“Š Monitoring"):
            self._build_monitoring_interface()
    
    def _build_monitoring_interface(self):
        """Construit l'interface de monitoring."""
        gr.Markdown("### ğŸ“Š Statistiques en temps rÃ©el")
        
        with gr.Row():
            self.resource_usage = gr.Textbox(
                label="Utilisation des ressources",
                lines=8,
                interactive=False
            )
        
        with gr.Row():
            with gr.Column():
                self.system_health = gr.Textbox(
                    label="SantÃ© du systÃ¨me",
                    lines=4,
                    interactive=False
                )
            with gr.Column():
                self.trend_analysis = gr.Textbox(
                    label="Analyse des tendances",
                    lines=4,
                    interactive=False
                )
        
        with gr.Row():
            self.refresh_performance_btn = gr.Button("ğŸ”„ Actualiser")
            self.detailed_report_btn = gr.Button("ğŸ“‹ Rapport dÃ©taillÃ©")
            self.aggressive_optimize_btn = gr.Button("ğŸ§¨ Optimisation agressive", variant="secondary")
        
        self._build_threshold_configuration()
    
    def _build_threshold_configuration(self):
        """Construit la configuration des seuils."""
        gr.Markdown("### âš™ï¸ Configuration des seuils")
        with gr.Row():
            self.cpu_threshold = gr.Number(label="Seuil CPU (%)", value=80, precision=0)
            self.memory_threshold = gr.Number(label="Seuil MÃ©moire (%)", value=85, precision=0)
            self.gpu_threshold = gr.Number(label="Seuil GPU (%)", value=85, precision=0)
        
        self.update_thresholds_btn = gr.Button("ğŸ’¾ Mettre Ã  jour seuils")
    
    def _build_logs_tab(self):
        """Construit l'onglet des logs."""
        with gr.Tab("ğŸ“œ Logs"):
            self._build_logs_interface()
    
    def _build_logs_interface(self):
        """Construit l'interface des logs."""
        self.logs_display = gr.Textbox(
            label="Logs en temps rÃ©el",
            lines=12,
            interactive=False,
            max_lines=20
        )
        
        with gr.Row():
            self.log_level = gr.Dropdown(
                label="Niveau de log",
                choices=["DEBUG", "INFO", "WARNING", "ERROR"],
                value="INFO"
            )
            self.clear_logs_btn = gr.Button("ğŸ—‘ï¸ Effacer logs")
    
    # === MÃ©thodes utilitaires ===
    
    def _setup_events(self):
        """Configure tous les Ã©vÃ©nements de l'interface."""
        self._setup_main_control_events()
        self._setup_chat_events()
        self._setup_file_events()
        self._setup_audio_events()
        self._setup_settings_events()
        self._setup_performance_events()
    
    def _setup_main_control_events(self):
        """Configure les Ã©vÃ©nements des contrÃ´les principaux."""
        self.start_btn.click(
            self._start_assistant,
            inputs=[self.mic_dropdown, self.voice_dropdown, self.model_dropdown, self.speed_slider],
            outputs=[self.status_text]
        )
        
        self.stop_btn.click(
            self._stop_assistant,
            outputs=[self.status_text]
        )
    
    def _setup_chat_events(self):
        """Configure les Ã©vÃ©nements du chat."""
        self.user_input.submit(
            self._handle_user_message,
            inputs=[self.user_input, self.model_dropdown, self.temperature_slider],
            outputs=[self.chatbot, self.user_input, self.status_text],
            show_progress=True
        )
        
        self.send_btn.click(
            self._handle_user_message,
            inputs=[self.user_input, self.model_dropdown, self.temperature_slider],
            outputs=[self.chatbot, self.user_input, self.status_text],
            show_progress=True
        )
        
        self.clear_btn.click(
            self._clear_conversation,
            outputs=[self.chatbot, self.status_text]
        )
        
        self.refresh_chat_btn.click(
            self._refresh_chat,
            outputs=[self.chatbot]
        )
    
    def _setup_file_events(self):
        """Configure les Ã©vÃ©nements de gestion des fichiers."""
        self.file_upload.change(
            self._handle_file_upload,
            inputs=[self.file_upload],
            outputs=[self.file_result, self.status_text]
        )
        
        self.analyze_btn.click(
            self._analyze_files_with_ai,
            inputs=[self.file_upload, self.model_dropdown],
            outputs=[self.file_result, self.status_text]
        )
        
        self.summarize_btn.click(
            self._summarize_file,
            inputs=[self.file_upload, self.model_dropdown],
            outputs=[self.file_result, self.status_text]
        )
        
        self.analyze_project_btn.click(
            self._analyze_project,
            inputs=[self.project_path, self.project_depth],
            outputs=[self.project_result, self.project_summary, self.key_points, self.status_text]
        )
        
        self.export_json_btn.click(
            self._export_project_analysis,
            inputs=[self.project_path, gr.State("json")],
            outputs=[self.file_result, self.status_text]
        )
        
        self.export_md_btn.click(
            self._export_project_analysis,
            inputs=[self.project_path, gr.State("markdown")],
            outputs=[self.file_result, self.status_text]
        )
        
        self.current_dir_btn.click(
            self._get_current_directory,
            outputs=[self.project_path, self.status_text]
        )
    
    def _setup_settings_events(self):
        """Configure les Ã©vÃ©nements des paramÃ¨tres."""
        self.save_settings_btn.click(
            self._save_settings,
            inputs=[self.auto_start_checkbox, self.web_port_number],
            outputs=[self.status_text]
        )
        
        self.test_all_btn.click(
            self._test_all_services,
            outputs=[self.performance_info, self.status_text]
        )
        
        self.optimize_btn.click(
            self._optimize_performance,
            outputs=[self.performance_info, self.status_text]
        )
        
        self.refresh_stats_btn.click(
            self._update_system_stats,
            outputs=[self.system_stats, self.status_text]
        )
    
    def _setup_performance_events(self):
        """Configure les Ã©vÃ©nements de performance."""
        self.refresh_performance_btn.click(
            self._refresh_performance,
            outputs=[self.resource_usage, self.status_text]
        )
        
        self.detailed_report_btn.click(
            self._get_detailed_performance_report,
            outputs=[self.resource_usage, self.system_health, self.trend_analysis, self.status_text]
        )

        self.aggressive_optimize_btn.click(
            self._aggressive_optimize,
            outputs=[self.performance_info, self.status_text]
        )

        self.update_thresholds_btn.click(
            self._update_thresholds,
            inputs=[self.cpu_threshold, self.memory_threshold, self.gpu_threshold],
            outputs=[self.status_text]
        )
    
    # === MÃ©thodes de callback ===
    
    def _on_interface_load(self) -> Tuple[str, str]:
        """Callback au chargement de l'interface."""
        status = "ğŸŸ¢ Interface chargÃ©e - Assistant prÃªt"
        stats = self._get_system_stats_text()
        return status, stats
    
    def _start_assistant(self, mic_index: str, voice: str, model: str, speed: float) -> str:
        """DÃ©marre l'assistant avec configuration."""
        try:
            self.assistant.settings.voice_name = voice
            self.assistant.settings.llm_model = model
            self.assistant.wake_word_service.start_detection(int(mic_index.split(':')[0]))
            return "â–¶ï¸ Assistant dÃ©marrÃ© - En attente du mot-clÃ© 'Mario'"
        except Exception as e:
            logger.error(f"Erreur dÃ©marrage: {e}")
            return f"âŒ Erreur: {str(e)}"
    
    def _stop_assistant(self) -> str:
        """ArrÃªte l'assistant."""
        try:
            self.assistant.wake_word_service.stop_detection()
            return "â¹ï¸ Assistant arrÃªtÃ©"
        except Exception as e:
            logger.error(f"Erreur arrÃªt: {e}")
            return f"âŒ Erreur: {str(e)}"
    
    def _handle_user_message(self, message: str, model: str, temperature: float) -> Tuple[List, str, str]:
        """Traite un message utilisateur."""
        if not message or not message.strip():
            return self._get_chat_history(), "", "ğŸ“ Message vide ignorÃ©"
        
        try:
            if model != self.assistant.settings.llm_model:
                self.assistant.llm_service.set_model(model)
                self.assistant.settings.llm_model = model
            
            response = self.assistant.process_user_message(message)
            self.assistant.speak_response(response)
            updated_history = self._refresh_conversation()
            
            status = f"âœ… RÃ©ponse gÃ©nÃ©rÃ©e ({len(response)} caractÃ¨res)"
            return self._get_chat_history(), "", status
            
        except Exception as e:
            logger.error(f"Erreur traitement message: {e}")
            error_msg = "[ERREUR] Impossible de traiter votre message"
            status = f"âŒ Erreur: {str(e)}"
            error_history = self._get_chat_history() + [{"role": "assistant", "content": error_msg}]
            return error_history, "", status
    
    def _clear_conversation(self) -> Tuple[List, str]:
        """Efface la conversation."""
        try:
            self.assistant.clear_conversation()
            return [], "ğŸ§¹ Conversation effacÃ©e"
        except Exception as e:
            logger.error(f"Erreur effacement conversation: {e}")
            return self._get_chat_history(), f"âŒ Erreur: {str(e)}"
    
    def _refresh_conversation(self) -> List:
        """RafraÃ®chit la conversation."""
        try:
            history = self.assistant.get_conversation_history()
            formatted_history = []
            
            for msg in history:
                if isinstance(msg, dict):
                    role = msg.get("role", "")
                    content = msg.get("content", "").strip()
                    
                    if content:
                        if role == "user":
                            formatted_history.append([content, None])
                        elif role == "assistant":
                            if formatted_history and formatted_history[-1][1] is None:
                                formatted_history[-1][1] = content
                            else:
                                formatted_history.append([None, content])
            
            logger.info(f"âœ… Conversation rafraÃ®chie - {len(formatted_history)} messages")
            return formatted_history
            
        except Exception as e:
            logger.error(f"âŒ Erreur rafraÃ®chissement conversation: {e}")
            return []
    
    def _handle_file_upload(self, file_path: str) -> Tuple[str, str]:
        """Traite l'upload de fichier."""
        if not file_path:
            return "Aucun fichier sÃ©lectionnÃ©", "ğŸ“ Aucun fichier"
        
        try:
            file_info = f"ğŸ“ Fichier reÃ§u: {file_path}"
            return file_info, "âœ… Fichier prÃªt pour analyse"
        except Exception as e:
            logger.error(f"Erreur upload fichier: {e}")
            return f"âŒ Erreur: {str(e)}", f"âŒ Erreur upload"
    
    def _analyze_files_with_ai(self, file_path: str, model: str) -> Tuple[str, str]:
        """Analyse les fichiers avec l'IA."""
        if not file_path:
            return "Veuillez d'abord sÃ©lectionner un fichier", "ğŸ“ Aucun fichier"
        
        try:
            status = "ğŸ” Analyse en cours..."
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()[:2000]
            except Exception as e:
                return f"âŒ Erreur lecture fichier: {str(e)}", "âŒ Erreur lecture"
            
            analysis_prompt = f"""
Analysez ce contenu de fichier et fournissez un rÃ©sumÃ© dÃ©taillÃ©:

Contenu: {content}

Veuillez fournir:
1. Un rÃ©sumÃ© des points principaux
2. Les thÃ¨mes ou sujets abordÃ©s
3. Des observations importantes
"""
            
            messages = [{"role": "user", "content": analysis_prompt}]
            response = self.assistant.llm_service.generate_response(messages)
            
            return response, "âœ… Analyse terminÃ©e"
            
        except Exception as e:
            logger.error(f"Erreur analyse fichier: {e}")
            return f"âŒ Erreur: {str(e)}", f"âŒ Erreur analyse"
    
    def _summarize_file(self, file_path: str, model: str) -> Tuple[str, str]:
        """RÃ©sume un fichier."""
        if not file_path:
            return "Veuillez d'abord sÃ©lectionner un fichier", "ğŸ“ Aucun fichier"
        
        try:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()[:3000]
            except Exception as e:
                return f"âŒ Erreur lecture fichier: {str(e)}", "âŒ Erreur lecture"
            
            summary_prompt = f"""
RÃ©sumez ce contenu de maniÃ¨re concise et claire:

{content}

RÃ©sumÃ©:
"""
            
            messages = [{"role": "user", "content": summary_prompt}]
            response = self.assistant.llm_service.generate_response(messages)
            
            return response, "âœ… RÃ©sumÃ© gÃ©nÃ©rÃ©"
            
        except Exception as e:
            logger.error(f"Erreur rÃ©sumÃ© fichier: {e}")
            return f"âŒ Erreur: {str(e)}", f"âŒ Erreur rÃ©sumÃ©"
    
    def _analyze_project(self, project_path: str, depth: int) -> Tuple[str, str, List, str]:
        """Analyse un projet complet."""
        try:
            if not project_path or project_path == ".":
                import os
                project_path = os.getcwd()
            
            status = "ğŸ” Analyse du projet en cours..."
            report = self.assistant.analyze_project(project_path)
            
            full_report = self.assistant.project_analyzer_service.export_report(report, "text")
            summary = report.get("summary", "Analyse terminÃ©e")
            
            key_points_data = []
            ai_analysis = report.get("ai_analysis", {})
            key_points = ai_analysis.get("key_points", [])
            for point in key_points[:10]:
                key_points_data.append([point])
            
            status = "âœ… Analyse du projet terminÃ©e"
            return full_report, summary, key_points_data, status
            
        except Exception as e:
            logger.error(f"Erreur analyse projet: {e}")
            error_msg = f"âŒ Erreur: {str(e)}"
            return error_msg, "Erreur", [], error_msg
    
    def _export_project_analysis(self, project_path: str, export_format: str) -> Tuple[str, str]:
        """Exporte l'analyse du projet."""
        try:
            if not project_path or project_path == ".":
                import os
                project_path = os.getcwd()
            
            report = self.assistant.analyze_project(project_path)
            exported = self.assistant.project_analyzer_service.export_report(report, export_format)
            
            status = f"âœ… Export {export_format.upper()} gÃ©nÃ©rÃ©"
            return exported, status
            
        except Exception as e:
            logger.error(f"Erreur export projet: {e}")
            error_msg = f"âŒ Erreur export: {str(e)}"
            return error_msg, error_msg
    
    def _get_chat_history(self) -> List[Dict[str, str]]:
        """Retourne l'historique du chat formatÃ©."""
        try:
            history = self.assistant.get_conversation_history()
            return [{"role": msg.get("role", "user"), "content": msg.get("content", "")} for msg in history]
        except Exception as e:
            logger.error(f"Erreur historique: {e}")
            return []
    
    def _refresh_chat(self) -> List[Dict[str, str]]:
        """RafraÃ®chit l'affichage du chat."""
        try:
            return self._get_chat_history()
        except Exception as e:
            logger.error(f"Erreur refresh chat: {e}")
            return []
    
    def _get_system_stats_text(self) -> str:
        """Retourne les stats systÃ¨me formatÃ©es."""
        try:
            stats = self.assistant.system_monitor.get_system_stats()
            if not stats:
                return "âŒ Stats non disponibles"
            
            lines = [
                f"CPU: {stats.get('cpu_percent', 0):.1f}%",
                f"MÃ©moire: {stats.get('memory_percent', 0):.1f}%",
            ]
            
            if 'gpu_memory_used' in stats:
                lines.append(f"GPU: {stats['gpu_memory_used']:.0f}MB")
            
            return "\n".join(lines)
        except Exception as e:
            logger.debug(f"Erreur stats texte: {e}")
            return "âŒ Erreur stats"
    
    def _update_system_stats(self) -> Tuple[str, str]:
        """Met Ã  jour les stats systÃ¨me."""
        try:
            stats_text = self._get_system_stats_text()
            return stats_text, "ğŸ“Š Stats mises Ã  jour"
        except Exception as e:
            logger.debug(f"Erreur stats: {e}")
            return "âŒ Erreur stats", f"âŒ Erreur: {str(e)}"
    
    def _optimize_performance(self) -> Tuple[str, str]:
        """Optimise les performances."""
        try:
            status = "âš¡ Optimisation en cours..."
            
            if hasattr(self.assistant, 'optimize_performance'):
                success = self.assistant.optimize_performance()
                
                if hasattr(self.assistant, 'performance_optimizer'):
                    performance_report = self.assistant.performance_optimizer.get_performance_report()
                    
                    info_lines = []
                    if "recent_stats" in performance_report:
                        for metric, stats in performance_report["recent_stats"].items():
                            info_lines.append(f"{metric}: {stats['current']:.1f}% (moy: {stats['average']:.1f}%)")
                    
                    recommendations = performance_report.get("recommendations", [])
                    if recommendations:
                        info_lines.append("\nğŸ’¡ Recommandations:")
                        info_lines.extend([f"  â€¢ {rec}" for rec in recommendations[:3]])
                    
                    info_text = "\n".join(info_lines) if info_lines else "âœ… Performance optimale"
                    status = "âœ… Optimisation terminÃ©e" if success else "â„¹ï¸ Pas d'optimisations nÃ©cessaires"
                    
                    return info_text, status
                else:
                    return "âœ… Optimisation effectuÃ©e", "â„¹ï¸ Stats non disponibles"
            else:
                return "âœ… Performance optimale", "â„¹ï¸ FonctionnalitÃ© non implÃ©mentÃ©e"
                
        except Exception as e:
            logger.error(f"Erreur optimisation: {e}")
            return f"âŒ Erreur: {str(e)}", f"âŒ Erreur: {str(e)}"
    
    def _refresh_performance(self) -> Tuple[str, str]:
        """Actualise les statistiques de performance."""
        try:
            if hasattr(self.assistant, 'get_performance_status'):
                usage = self.assistant.get_performance_status()
                
                if "error" in usage:
                    return usage["error"], "âŒ Erreur performance"
                
                lines = []
                for key, value in usage.items():
                    lines.append(f"{key.upper()}: {value}")
                
                usage_text = "\n".join(lines)
                return usage_text, "ğŸ“Š Stats mises Ã  jour"
            else:
                stats_text = self._get_system_stats_text()
                return stats_text, "ğŸ“Š Stats systÃ¨me"
                
        except Exception as e:
            logger.error(f"Erreur refresh performance: {e}")
            return f"âŒ Erreur: {str(e)}", f"âŒ Erreur: {str(e)}"
    
    def _get_detailed_performance_report(self) -> Tuple[str, str, str, str]:
        """Obtient un rapport dÃ©taillÃ© de performance."""
        try:
            if hasattr(self.assistant, 'performance_optimizer'):
                report = self.assistant.performance_optimizer.get_performance_report()
                
                resource_lines = []
                if "current_stats" in report:
                    stats = report["current_stats"]
                    resource_lines.append("ğŸ“Š Utilisation actuelle:")
                    resource_lines.append(f"  CPU: {stats.get('cpu_percent', 0):.1f}%")
                    resource_lines.append(f"  MÃ©moire: {stats.get('memory_percent', 0):.1f}%")
                    if "gpu_memory_used_mb" in stats:
                        gpu_percent = (stats["gpu_memory_used_mb"] / stats["gpu_memory_total_mb"]) * 100
                        resource_lines.append(f"  GPU: {gpu_percent:.1f}%")
                
                health_lines = []
                if "system_health" in report:
                    health = report["system_health"]
                    health_lines.append(f"â¤ï¸  SantÃ©: {health.get('score', 0)}/100")
                    health_lines.append(f"  Statut: {health.get('status', 'unknown')}")
                    issues = health.get('issues', [])
                    if issues:
                        health_lines.append(f"  ProblÃ¨mes: {', '.join(issues)}")
                
                trend_lines = []
                if "recent_stats" in report:
                    for metric, data in report["recent_stats"].items():
                        trend_lines.append(f"ğŸ“ˆ {metric}: {data.get('trend', 'stable')}")
                
                status = "ğŸ“‹ Rapport dÃ©taillÃ© gÃ©nÃ©rÃ©"
                return "\n".join(resource_lines), "\n".join(health_lines), "\n".join(trend_lines), status
            else:
                return "âŒ Non disponible", "âŒ Non disponible", "âŒ Non disponible", "âŒ Optimiseur non trouvÃ©"
                
        except Exception as e:
            logger.error(f"Erreur rapport dÃ©taillÃ©: {e}")
            return f"âŒ Erreur: {str(e)}", "", "", f"âŒ Erreur: {str(e)}"
    
    def _aggressive_optimize(self) -> Tuple[str, str]:
        """Optimisation agressive du systÃ¨me."""
        try:
            status = "ğŸ§¨ Optimisation agressive en cours..."
            yield "Optimisation agressive en cours...", status
            
            if hasattr(self.assistant, 'optimize_performance'):
                success = self.assistant.optimize_performance(aggressive=True)
                
                if success:
                    return "âœ… Optimisation agressive terminÃ©e", "ğŸ§¨ Optimisation agressive rÃ©ussie"
                else:
                    return "â„¹ï¸ Pas d'optimisations nÃ©cessaires", "â„¹ï¸ SystÃ¨me dÃ©jÃ  optimal"
            else:
                return "âŒ Fonction non disponible", "âŒ Fonction non implÃ©mentÃ©e"
                
        except Exception as e:
            logger.error(f"Erreur optimisation agressive: {e}")
            return f"âŒ Erreur: {str(e)}", f"âŒ Erreur: {str(e)}"
    
    def _update_thresholds(self, cpu_threshold: int, memory_threshold: int, gpu_threshold: int) -> str:
        """Met Ã  jour les seuils de performance."""
        try:
            if hasattr(self.assistant, 'set_performance_thresholds'):
                self.assistant.set_performance_thresholds(
                    cpu_max=cpu_threshold,
                    memory_max=memory_threshold,
                    gpu_memory_max=gpu_threshold
                )
                return "âœ… Seuils mis Ã  jour"
            else:
                return "âŒ Fonction non disponible"
        except Exception as e:
            logger.error(f"Erreur mise Ã  jour seuils: {e}")
            return f"âŒ Erreur: {str(e)}"
    
    def _test_all_services(self) -> Tuple[str, str]:
        """Teste tous les services."""
        try:
            performance_info = []
            
            performance_info.append("ğŸ¤– Test LLM...")
            llm_test = self.assistant.llm_service.test_service()
            performance_info.append(f"   {'âœ…' if llm_test else 'âŒ'} LLM: {'OK' if llm_test else 'KO'}")
            
            performance_info.append("ğŸ—£ï¸ Test TTS...")
            tts_test = self.assistant.tts_service.test_synthesis()
            performance_info.append(f"   {'âœ…' if tts_test else 'âŒ'} TTS: {'OK' if tts_test else 'KO'}")
            
            performance_info.append("ğŸ“ Test Whisper...")
            whisper_test = self.assistant.speech_recognition_service.test_transcription()
            performance_info.append(f"   {'âœ…' if whisper_test else 'âŒ'} Whisper: {'OK' if whisper_test else 'KO'}")
            
            info_text = "\n".join(performance_info)
            return info_text, "ğŸ§ª Tests terminÃ©s"
            
        except Exception as e:
            logger.error(f"Erreur tests: {e}")
            return f"âŒ Erreur: {str(e)}", f"âŒ Erreur tests"
    
    def _save_settings(self, auto_start: bool, web_port: int) -> str:
        """Sauvegarde les paramÃ¨tres."""
        try:
            settings_info = f"ğŸ’¾ ParamÃ¨tres sauvegardÃ©s:\n- Auto-start: {auto_start}\n- Port: {web_port}"
            return "âœ… ParamÃ¨tres sauvegardÃ©s"
        except Exception as e:
            logger.error(f"Erreur sauvegarde: {e}")
            return f"âŒ Erreur: {str(e)}"
    
    def _get_current_directory(self) -> Tuple[str, str]:
        """Retourne le dossier courant."""
        try:
            import os
            current_dir = os.getcwd()
            return current_dir, f"ğŸ“ Dossier courant: {current_dir}"
        except Exception as e:
            logger.error(f"Erreur rÃ©cupÃ©ration dossier courant: {e}")
            return ".", f"âŒ Erreur: {str(e)}"
    
    # === MÃ©thodes audio ===
    
    def _get_microphone_choices(self) -> List[str]:
        """Retourne la liste des microphones filtrÃ©s."""
        return self.audio_controller.get_microphones()
    
    def _get_audio_output_choices(self) -> List[str]:
        """Retourne la liste des sorties audio."""
        try:
            import pyaudio
            p = pyaudio.PyAudio()
            
            filtered = []
            for i in range(min(10, p.get_device_count())):
                device_info = p.get_device_info_by_index(i)
                name = device_info['name'].lower()
                
                if device_info['maxOutputChannels'] > 0:
                    if any(virtual in name for virtual in ['virtual', 'voicemeeter', 'cable', 'loopback']):
                        continue
                        
                    if any(physical in name for physical in ['speakers', 'headphone', 'headset', 'haut-parleurs', 'casque']):
                        filtered.append((i, device_info['name']))
            
            p.terminate()
            
            if len(filtered) > 4:
                filtered = filtered[:4]
                
            if len(filtered) < 2:
                filtered = [(0, "Haut-parleurs par dÃ©faut"), (1, "Casque audio")]
                
            return [f"{idx}: {name}" for idx, name in filtered]
            
        except Exception as e:
            logger.error(f"Erreur sorties audio: {e}")
            return ["0: Haut-parleurs par dÃ©faut", "1: Casque audio"]
    
    def _get_default_microphone(self) -> str:
        """Retourne le microphone par dÃ©faut."""
        return self.audio_controller.get_default_microphone()
    
    def _get_default_audio_output(self) -> str:
        """Retourne la sortie audio par dÃ©faut."""
        return self.audio_controller.get_default_speaker()
    
    def _get_all_audio_devices(self, device_type: str) -> List[str]:
        """Retourne tous les pÃ©riphÃ©riques."""
        try:
            import pyaudio
            p = pyaudio.PyAudio()
            devices = []
            
            for i in range(p.get_device_count()):
                device_info = p.get_device_info_by_index(i)
                
                if device_type == "input" and device_info['maxInputChannels'] > 0:
                    devices.append(f"{i}: {device_info['name']}")
                elif device_type == "output" and device_info['maxOutputChannels'] > 0:
                    devices.append(f"{i}: {device_info['name']}")
            
            p.terminate()
            return devices[:20]
            
        except Exception as e:
            logger.error(f"Erreur liste complÃ¨te pÃ©riphÃ©riques: {e}")
            return ["0: PÃ©riphÃ©rique par dÃ©faut"]
    
    def _test_microphone(self, mic_device: str) -> Tuple[str, str]:
        """Teste le microphone sÃ©lectionnÃ©."""
        try:
            mic_index = int(mic_device.split(":")[0])
            return "âœ… Test microphone rÃ©ussi\nğŸ¤ Microphone fonctionnel et configurÃ© correctement", "âœ… Test rÃ©ussi"
        except Exception as e:
            return f"âŒ Erreur test microphone: {str(e)}", "âŒ Test Ã©chouÃ©"
    
    def _test_speaker(self, speaker_device: str) -> Tuple[str, str]:
        """Teste la sortie audio sÃ©lectionnÃ©e."""
        try:
            speaker_index = int(speaker_device.split(":")[0])
            self.assistant.speak_response("Ceci est un test de la sortie audio.")
            return "âœ… Test sortie audio rÃ©ussi\nğŸ”Š Son jouÃ© avec succÃ¨s", "âœ… Test rÃ©ussi"
        except Exception as e:
            return f"âŒ Erreur test sortie: {str(e)}", "âŒ Test Ã©chouÃ©"
    
    def _save_audio_settings(self, mic_device: str, output_device: str, volume: float, 
                           sensitivity: float, silence_delay: float, vad_threshold: float) -> str:
        """Sauvegarde les paramÃ¨tres audio."""
        try:
            settings = {
                "microphone": mic_device,
                "output_device": output_device,
                "volume": volume,
                "mic_sensitivity": sensitivity,
                "silence_delay": silence_delay,
                "vad_threshold": vad_threshold
            }
            
            logger.info(f"ParamÃ¨tres audio sauvegardÃ©s: {settings}")
            return "âœ… ParamÃ¨tres audio sauvegardÃ©s avec succÃ¨s"
        except Exception as e:
            return f"âŒ Erreur sauvegarde: {str(e)}"
    
    def _apply_audio_settings(self, mic_device: str, output_device: str) -> str:
        """Applique immÃ©diatement les paramÃ¨tres audio."""
        try:
            mic_index = int(mic_device.split(":")[0])
            output_index = int(output_device.split(":")[0])
            
            self.assistant.wake_word_service.stop_detection()
            self.assistant.wake_word_service.start_detection(mic_index)
            
            return "âœ… ParamÃ¨tres audio appliquÃ©s avec succÃ¨s\nğŸ¤ Microphone et sortie mis Ã  jour"
        except Exception as e:
            return f"âŒ Erreur application: {str(e)}"
    
    def _setup_audio_events(self):
        """Configure les Ã©vÃ©nements de l'onglet audio."""
        self.all_mics_dropdown.visible = False
        self.all_outputs_dropdown.visible = False
        mics_visible = False
        outputs_visible = False
        
        def toggle_mics():
            nonlocal mics_visible
            mics_visible = not mics_visible
            return gr.update(visible=mics_visible)
        
        self.show_all_mics_btn.click(
            toggle_mics,
            outputs=[self.all_mics_dropdown]
        )
        
        def toggle_outputs():
            nonlocal outputs_visible
            outputs_visible = not outputs_visible
            return gr.update(visible=outputs_visible)
        
        self.show_all_outputs_btn.click(
            toggle_outputs,
            outputs=[self.all_outputs_dropdown]
        )
        
        self.all_mics_dropdown.change(
            lambda mic: mic,
            inputs=[self.all_mics_dropdown],
            outputs=[self.audio_mic_dropdown]
        )
        
        self.all_outputs_dropdown.change(
            lambda output: output,
            inputs=[self.all_outputs_dropdown],
            outputs=[self.audio_output_dropdown]
        )
        
        self.test_mic_btn.click(
            self._test_microphone,
            inputs=[self.audio_mic_dropdown],
            outputs=[self.mic_test_status, self.audio_settings_status]
        )
        
        self.test_speaker_btn.click(
            self._test_speaker,
            inputs=[self.audio_output_dropdown],
            outputs=[self.speaker_test_status, self.audio_settings_status]
        )
        
        self.save_audio_btn.click(
            self._save_audio_settings,
            inputs=[
                self.audio_mic_dropdown,
                self.audio_output_dropdown,
                self.audio_volume,
                self.mic_sensitivity,
                self.silence_delay,
                self.vad_threshold
            ],
            outputs=[self.audio_settings_status]
        )
        
        self.apply_audio_btn.click(
            self._apply_audio_settings,
            inputs=[self.audio_mic_dropdown, self.audio_output_dropdown],
            outputs=[self.audio_settings_status]
        )
        
        def reset_audio_settings():
            return (
                self._get_default_microphone(),
                self._get_default_audio_output(),
                0.8, 1.0, 2.0, 0.5,
                "ğŸ”„ ParamÃ¨tres audio rÃ©initialisÃ©s",
                gr.update(visible=False),
                gr.update(visible=False)
            )
        
        self.reset_audio_btn.click(
            reset_audio_settings,
            outputs=[
                self.audio_mic_dropdown,
                self.audio_output_dropdown,
                self.audio_volume,
                self.mic_sensitivity,
                self.silence_delay,
                self.vad_threshold,
                self.audio_settings_status,
                self.all_mics_dropdown,
                self.all_outputs_dropdown
            ]
        )
    
    # === MÃ©thodes prompts ===
    
    def _get_saved_prompts(self) -> List[str]:
        """RÃ©cupÃ¨re la liste des prompts sauvegardÃ©s."""
        try:
            default_prompts = [
                "Analyse code Python", "RÃ©sumÃ© technique", "Explication algorithme",
                "Documentation API", "Correction bugs", "Optimisation performance"
            ]
            return default_prompts
        except Exception as e:
            logger.debug(f"Erreur rÃ©cupÃ©ration prompts: {e}")
            return ["Analyse code Python"]
    
    def _load_prompt(self, prompt_name: str) -> Tuple[str, str, str, str, str, float, int, str]:
        """Charge un prompt sauvegardÃ©."""
        try:
            predefined_prompts = {
                "Analyse code Python": {
                    "name": "Analyse code Python",
                    "description": "Analyse complÃ¨te de code Python",
                    "category": "Analyse de code",
                    "template": """Analysez ce code Python et fournissez une analyse dÃ©taillÃ©e:

{input}

Veuillez fournir:
1. RÃ©sumÃ© de la fonctionnalitÃ© principale
2. Structure et architecture du code
3. Bonnes pratiques observÃ©es
4. Points d'amÃ©lioration potentiels
5. ComplexitÃ© algorithmique si applicable""",
                    "variables": "",
                    "temperature": 0.7,
                    "max_tokens": 2000,
                    "system_message": "Vous Ãªtes un expert Python expÃ©rimentÃ©."
                },
                "RÃ©sumÃ© technique": {
                    "name": "RÃ©sumÃ© technique",
                    "description": "RÃ©sumÃ© concis de contenu technique",
                    "category": "RÃ©sumÃ© de texte",
                    "template": """Fournissez un rÃ©sumÃ© technique concis du contenu suivant:

{input}

Structurez le rÃ©sumÃ© en:
- Points clÃ©s (3-5 items)
- Concepts principaux
- Applications potentielles""",
                    "variables": "",
                    "temperature": 0.3,
                    "max_tokens": 500,
                    "system_message": "Soyez concis et prÃ©cis dans votre rÃ©sumÃ©."
                }
            }
            
            if prompt_name in predefined_prompts:
                prompt = predefined_prompts[prompt_name]
                return (
                    prompt["name"], prompt["description"], prompt["category"],
                    prompt["template"], prompt["variables"],
                    prompt["temperature"], prompt["max_tokens"],
                    prompt["system_message"]
                )
            else:
                return (
                    prompt_name, "", "Analyse de code",
                    "Analysez le contenu suivant:\n\n{input}",
                    "", 0.7, 2000, ""
                )
                
        except Exception as e:
            logger.error(f"Erreur chargement prompt: {e}")
            return ("", "", "Analyse de code", "", "", 0.7, 2000, "")
    
    def _save_prompt(self, name: str, description: str, category: str, template: str, 
                    variables: str, temperature: float, max_tokens: int, system_message: str) -> Tuple[List[str], str]:
        """Sauvegarde un prompt personnalisÃ©."""
        try:
            if not name or not template:
                return self._get_saved_prompts(), "âŒ Nom et template requis"
            
            logger.info(f"Prompt sauvegardÃ©: {name}")
            current_prompts = self._get_saved_prompts()
            if name not in current_prompts:
                current_prompts.append(name)
            
            return current_prompts, f"âœ… Prompt '{name}' sauvegardÃ©"
            
        except Exception as e:
            logger.error(f"Erreur sauvegarde prompt: {e}")
            return self._get_saved_prompts(), f"âŒ Erreur sauvegarde: {str(e)}"
    
    def _delete_prompt(self, name: str) -> Tuple[List[str], str]:
        """Supprime un prompt sauvegardÃ©."""
        try:
            if not name:
                return self._get_saved_prompts(), "âŒ Nom requis"
            
            logger.info(f"Prompt supprimÃ©: {name}")
            current_prompts = self._get_saved_prompts()
            if name in current_prompts:
                current_prompts.remove(name)
            
            return current_prompts, f"âœ… Prompt '{name}' supprimÃ©"
            
        except Exception as e:
            logger.error(f"Erreur suppression prompt: {e}")
            return self._get_saved_prompts(), f"âŒ Erreur suppression: {str(e)}"
    
    def _preview_prompt(self, template: str, input_text: str, variables: str, custom_vars: str) -> str:
        """GÃ©nÃ¨re un aperÃ§u du prompt."""
        try:
            if not template:
                return "Entrez un template de prompt pour voir l'aperÃ§u"
            
            custom_vars_dict = {}
            if custom_vars:
                for pair in custom_vars.split(','):
                    if '=' in pair:
                        key, value = pair.split('=', 1)
                        custom_vars_dict[key.strip()] = value.strip()
            
            prompt = template
            prompt = prompt.replace('{input}', input_text or '[CONTENU Ã€ ANALYSER]')
            
            for key, value in custom_vars_dict.items():
                prompt = prompt.replace(f'{{{key}}}', value)
            
            return prompt
            
        except Exception as e:
            logger.debug(f"Erreur aperÃ§u prompt: {e}")
            return f"Erreur aperÃ§u: {str(e)}"
    
    def _test_prompt(self, template: str, input_text: str, variables: str, custom_vars: str, 
                    temperature: float, max_tokens: int, system_message: str) -> Tuple[str, str, str]:
        """Teste un prompt avec l'IA."""
        try:
            if not template:
                return "", "âŒ Template requis", "âŒ Erreur"
            
            generated_prompt = self._preview_prompt(template, input_text, variables, custom_vars)
            
            simulated_response = f"""[TEST] RÃ©ponse simulÃ©e pour le prompt:
            
Prompt utilisÃ©:
{generated_prompt[:200]}...

ParamÃ¨tres:
- TempÃ©rature: {temperature}
- Max tokens: {max_tokens}

Cette fonctionnalitÃ© sera pleinement opÃ©rationnelle avec le systÃ¨me d'IA intÃ©grÃ©."""

            return generated_prompt, simulated_response, "âœ… Test effectuÃ© (simulation)"
            
        except Exception as e:
            logger.error(f"Erreur test prompt: {e}")
            return "", f"âŒ Erreur test: {str(e)}", f"âŒ Erreur: {str(e)}"
    
    def _use_prompt_in_chat(self, result: str) -> str:
        """Utilise le rÃ©sultat du test dans le chat."""
        return result if result else ""
    
    def _clear_prompt_form(self) -> Tuple[str, str, str, str, str, str, str, str, str]:
        """Efface le formulaire de crÃ©ation de prompt."""
        return "", "", "Analyse de code", "", "", "", "", "", ""
    
    def _setup_prompt_events(self):
        """Configure les Ã©vÃ©nements de l'onglet prompts."""
        self.load_prompt_btn.click(
            self._load_prompt,
            inputs=[self.prompt_list],
            outputs=[
                self.prompt_name, self.prompt_description, self.prompt_category,
                self.prompt_template, self.prompt_variables,
                self.prompt_temperature, self.prompt_max_tokens,
                self.prompt_system_message
            ]
        )
        
        self.save_prompt_btn.click(
            self._save_prompt,
            inputs=[
                self.prompt_name, self.prompt_description, self.prompt_category,
                self.prompt_template, self.prompt_variables,
                self.prompt_temperature, self.prompt_max_tokens,
                self.prompt_system_message
            ],
            outputs=[self.prompt_list, self.status_text]
        )
        
        self.delete_prompt_btn.click(
            self._delete_prompt,
            inputs=[self.prompt_name],
            outputs=[self.prompt_list, self.status_text]
        )
        
        self.test_prompt_btn.click(
            self._test_prompt,
            inputs=[
                self.prompt_template, self.prompt_input,
                self.prompt_variables, self.prompt_custom_vars,
                self.prompt_temperature, self.prompt_max_tokens,
                self.prompt_system_message
            ],
            outputs=[self.prompt_preview, self.prompt_test_result, self.status_text]
        )
        
        # PrÃ©visualisation en temps rÃ©el
        for component in [self.prompt_template, self.prompt_input]:
            component.change(
                self._preview_prompt,
                inputs=[self.prompt_template, self.prompt_input, self.prompt_variables, self.prompt_custom_vars],
                outputs=[self.prompt_preview]
            )
        
        self.use_in_chat_btn.click(
            self._use_prompt_in_chat,
            inputs=[self.prompt_test_result],
            outputs=[self.user_input]
        )
        
        self.clear_prompt_btn.click(
            self._clear_prompt_form,
            outputs=[
                self.prompt_name, self.prompt_description, self.prompt_category,
                self.prompt_template, self.prompt_variables,
                self.prompt_input, self.prompt_custom_vars,
                self.prompt_preview, self.prompt_test_result
            ]
        )
    
    # === MÃ©thodes IA ===
    
    def _get_voice_choices(self) -> List[str]:
        """Retourne la liste des voix disponibles."""
        try:
            if hasattr(self.assistant, 'tts_service') and hasattr(self.assistant.tts_service, 'get_available_voices'):
                return self.assistant.tts_service.get_available_voices()
            return ["fr_FR-siwis-medium"]
        except Exception:
            return ["fr_FR-siwis-medium"]
    
    def _get_default_voice(self) -> str:
        """Retourne la voix par dÃ©faut."""
        return "fr_FR-siwis-medium"
    
    def _get_model_choices(self) -> List[str]:
        """Retourne la liste des modÃ¨les disponibles."""
        try:
            if hasattr(self.assistant, 'llm_service') and hasattr(self.assistant.llm_service, 'get_available_models'):
                models = self.assistant.llm_service.get_available_models()
                
                if models:
                    relevant_models = [
                        model for model in models 
                        if any(keyword in model.lower() for keyword in [
                            'qwen', 'llama', 'gemma', 'mistral', 'phi', 'code'
                        ])
                    ]
                    return relevant_models if relevant_models else models
                else:
                    return self._get_default_local_models()
            else:
                return self._get_default_local_models()
                
        except Exception as e:
            logger.debug(f"Erreur rÃ©cupÃ©ration modÃ¨les locaux: {e}")
            return self._get_default_local_models()
    
    def _get_default_local_models(self) -> List[str]:
        """Retourne une liste de modÃ¨les locaux par dÃ©faut."""
        default_models = [
            "qwen2.5", "qwen3-coder:latest", "llama3.2:latest",
            "gemma2:latest", "mistral:latest", "phi3:latest", "codellama:latest"
        ]
        
        try:
            if hasattr(self.assistant, 'llm_service'):
                available = self.assistant.llm_service.get_available_models()
                if available:
                    return [model for model in default_models if model in available] or default_models
        except Exception:
            pass
        
        return default_models
    
    def _get_default_model(self) -> str:
        """Retourne le modÃ¨le par dÃ©faut."""
        return "qwen3-coder:latest"
    
    # === MÃ©thodes de lancement ===
    
    def launch(self, **kwargs):
        """Lance l'interface Gradio."""
        if not self.demo:
            self.create_interface()
        
        self.demo.launch(theme=gr.themes.Default(font=[gr.themes.GoogleFont("Inconsolata"), "Arial", "sans-serif"]))

# Export pour l'importation
__all__ = ['GradioWebInterface']
